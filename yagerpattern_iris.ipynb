{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries \n",
    "import keras #library for neural network\n",
    "import pandas as pd #loading data in table form  \n",
    "import seaborn as sns #visualisation \n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import normalize #machine learning algorithm library\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "from keras.utils.vis_utils import plot_model\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLength  SepalWidth  PetalLength  PetalWidth  TYPE\n",
       "0            5.1         3.5          1.4         0.2     0\n",
       "1            4.9         3.0          1.4         0.2     0\n",
       "2            4.7         3.2          1.3         0.2     0\n",
       "3            4.6         3.1          1.5         0.2     0\n",
       "4            5.0         3.6          1.4         0.2     0\n",
       "..           ...         ...          ...         ...   ...\n",
       "145          6.7         3.0          5.2         2.3     2\n",
       "146          6.3         2.5          5.0         1.9     2\n",
       "147          6.4         3.1          5.5         1.8     2\n",
       "148          6.2         3.4          5.4         2.3     2\n",
       "149          5.9         3.0          5.1         1.8     2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data \n",
    "data=pd.read_csv(\"IrisData.csv\")\n",
    "col_names=list(data.columns.values)\n",
    "num_line = len(data.index)\n",
    "\n",
    "num_input=4\n",
    "num_output=3\n",
    "num_var=5\n",
    "clusters=3\n",
    "#print(\"Describing the data: \",data.describe())\n",
    "#print(\"Info of the data:\",data.info())\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLength  SepalWidth  PetalLength  PetalWidth  TYPE\n",
      "0            5.1         3.5          1.4         0.2     0\n",
      "1            4.9         3.0          1.4         0.2     0\n",
      "2            4.7         3.2          1.3         0.2     0\n",
      "3            4.6         3.1          1.5         0.2     0\n",
      "4            5.0         3.6          1.4         0.2     0\n",
      "..           ...         ...          ...         ...   ...\n",
      "145          6.7         3.0          5.2         2.3     2\n",
      "146          6.3         2.5          5.0         1.9     2\n",
      "147          6.4         3.1          5.5         1.8     2\n",
      "148          6.2         3.4          5.4         2.3     2\n",
      "149          5.9         3.0          5.1         1.8     2\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "train_num_line  30\n",
      "     SepalLength  SepalWidth  PetalLength  PetalWidth  TYPE\n",
      "0            5.1         3.5          1.4         0.2     0\n",
      "1            4.9         3.0          1.4         0.2     0\n",
      "2            4.7         3.2          1.3         0.2     0\n",
      "3            4.6         3.1          1.5         0.2     0\n",
      "4            5.0         3.6          1.4         0.2     0\n",
      "..           ...         ...          ...         ...   ...\n",
      "145          6.7         3.0          5.2         2.3     2\n",
      "146          6.3         2.5          5.0         1.9     2\n",
      "147          6.4         3.1          5.5         1.8     2\n",
      "148          6.2         3.4          5.4         2.3     2\n",
      "149          5.9         3.0          5.1         1.8     2\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "test_num_line 120\n"
     ]
    }
   ],
   "source": [
    "#Reading data \n",
    "train_num_line=int(num_line*0.2)\n",
    "test_num_line = num_line - train_num_line\n",
    "# test_num_line=num_line\n",
    "# train_num_line=num_line\n",
    "\n",
    "# Create data_train = initialise dataframe (80%)\n",
    "temp = np.array([[0.0 for i in range(train_num_line)] for j in range(num_var)]).T\n",
    "# Array to dataframe :\n",
    "data_train = pd.DataFrame(temp,columns=col_names)\n",
    "\n",
    "# Create data_train = initialise dataframe (80%)\n",
    "temp = np.array([[0.0 for i in range(test_num_line)] for j in range(num_var)]).T\n",
    "# Array to dataframe :\n",
    "data_test = pd.DataFrame(temp,columns=col_names)\n",
    "\n",
    "count = 0\n",
    "train_count=0\n",
    "test_count=0\n",
    "\n",
    "# # 20% train, 80% test\n",
    "# # 0,1 // 2,3 // 4,5 // 6,7 // 8,9\n",
    "# for i in range(num_line):\n",
    "#     if (count==8 or count ==9):\n",
    "#         data_train.iloc[train_count] = data.iloc[i]\n",
    "#         train_count=train_count+1\n",
    "#     else:\n",
    "#         data_test.iloc[test_count] = data.iloc[i]\n",
    "#         test_count=test_count+1\n",
    "#     count=count+1\n",
    "#     if count==10:\n",
    "#         count=0\n",
    "\n",
    "# ## odd even\n",
    "# for i in range(num_line):\n",
    "#     #even\n",
    "#     if (count==0):\n",
    "#         data_test.iloc[test_count] = data.iloc[i]\n",
    "#         test_count=test_count+1\n",
    "#         count=1\n",
    "#     ##odd\n",
    "#     else:\n",
    "#         data_train.iloc[train_count] = data.iloc[i]\n",
    "#         train_count=train_count+1\n",
    "#         count=0\n",
    "\n",
    "data_test=data\n",
    "data_train=data_test\n",
    "##odd\n",
    "print(data_train)\n",
    "print(\"train_num_line \",train_num_line)\n",
    "\n",
    "\n",
    "##even\n",
    "print(data_test)\n",
    "print(\"test_num_line\",test_num_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningConst = float(1/train_num_line)\n",
    "epsilon = 0.0005\n",
    "discreteSamplePoints=50\n",
    "mlvq_lwidth=1.5\n",
    "pfkp_lwidth=0.2\n",
    "c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network():\n",
    "  def __init__(self,dim):\n",
    "    self.num_layers=dim\n",
    "    self.layers = [layer]*dim\n",
    "    self.num_feature=0\n",
    "    self.num_pattern=0\n",
    "  def addLayers(self,i,layer):\n",
    "    self.layers[i]=layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer(network):\n",
    "  def __init__(self,dim,ipNeuron,x):\n",
    "    self.dim = dim\n",
    "    self.neus = [neuron]*dim\n",
    "    self.ipneus=[ipneuron]*dim\n",
    "    self.count=0\n",
    "    for i in range(dim):\n",
    "        if ipNeuron == 0:\n",
    "            self.neus[i]=neuron(dim)\n",
    "        else:\n",
    "            self.ipneus[i]=ipneuron(dim,i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuron(layer):\n",
    "  def __init__(self,dim):\n",
    "    self.name = None\n",
    "    self.value = 0\n",
    "    self.num_inputs = 0\n",
    "    self.input = [neuron]*num_input\n",
    "    self.wt= [0]*num_input\n",
    "    self.combFunc=-1\n",
    "    self.actFunc=-1\n",
    "    self.activation=0\n",
    "    self.ip_type=1\n",
    "    self.ipneu_input = [ipneuron]\n",
    "    self.actFunc_arg=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ipneuron(layer):\n",
    "  def __init__(self,dim,count,x):\n",
    "    self.numPt=discreteSamplePoints\n",
    "    self.ip_value=0\n",
    "    self.value=[0]*num_output #num_pattern\n",
    "    self.name=col_names[count]\n",
    "    self.mf = [[0 for i in range(discreteSamplePoints)] for j in range(num_output+1)] \n",
    "    for i in range(num_output+1):\n",
    "        for j in range(discreteSamplePoints):\n",
    "            #print((discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(num_output+1))))\n",
    "            self.mf[i][j]=x[(discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(num_output+1)))]\n",
    "    if(count==num_input-1):\n",
    "        count=count+1\n",
    "        for i in range(clusters+1):\n",
    "            for j in range(discreteSamplePoints):\n",
    "#                 print((discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(output_cluster+1))))\n",
    "                outmf[i][j]=x[(discreteSamplePoints*i)+j+(count*(discreteSamplePoints*(clusters+1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildConnections(source, dest, start, step, size): #layer2->layer3, 0-3\n",
    "    i=k=st=start\n",
    "    for i in range(dest.dim):\n",
    "        currneu=dest.neus[i]\n",
    "        #newneu=[None]*8\n",
    "        newneu=[neuron]*8\n",
    "        newwt=[0]*8\n",
    "        for k in range(currneu.num_inputs):\n",
    "            newneu[k] = currneu.input[k]\n",
    "            newwt[k] = currneu.wt[k]\n",
    "        currneu.input=newneu\n",
    "        currneu.wt = newwt\n",
    "        k=st\n",
    "        for k in range(st+size):\n",
    "            currneu.input[currneu.num_inputs]=source.neus[k]\n",
    "            currneu.wt[currneu.num_inputs]=0\n",
    "            currneu.num_inputs+=currneu.num_inputs\n",
    "        st+=step\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWinner(value,lyr):\n",
    "    winner=0\n",
    "    error=math.fabs(value-lyr.neus[0].value)\n",
    "    for i in range(1,lyr.dim):\n",
    "        temp=min(error, math.fabs(value-lyr.neus[i].value))\n",
    "        if temp<error:\n",
    "            error=temp\n",
    "            winner=i\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findWinner1(value,pt,numPt):\n",
    "    winner=0\n",
    "    error=math.fabs(value-pt[0])\n",
    "    for i in range(1,numPt):\n",
    "        temp=min(error, math.fabs(value-pt[i]))\n",
    "        if temp<error:\n",
    "            error=temp\n",
    "            winner=i\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dct(nw,data,ndx):\n",
    "    e1=0\n",
    "    le1=0\n",
    "    e2=0\n",
    "    le2=0\n",
    "    neighbours = 0\n",
    "    iterations=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    neighbours = int(nw.layers[2].dim/5);\n",
    "    interval = (max1-min1)/nw.layers[2].dim;\n",
    "    \n",
    "    for j in range(nw.layers[1].dim): \n",
    "        lyr = nw.layers[2]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].wt[j]=0\n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            e1+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            \n",
    "            \n",
    "            lyr = nw.layers[2];\n",
    "            winner2 = findWinner(data[k], lyr);\n",
    "            diff = math.fabs(data[k]-lyr.neus[winner2].value);\n",
    "            lyr.neus[winner2].wt[winner1] += learningConst*(1-diff/interval)\n",
    "            e2 += diff;\n",
    "            \n",
    "            \n",
    "            i=(winner2-1)\n",
    "            for l in range(2,neighbours+2):\n",
    "                if i>=0:\n",
    "                    diff = math.fabs(data[k]-lyr.neus[i].value)\n",
    "                    lyr.neus[i].wt[winner1] += learningConst/l*(1-diff/(l*interval));\n",
    "                i=i-1\n",
    "                \n",
    "            i=(winner2+1)\n",
    "            for l in range(2,neighbours+2):\n",
    "                if i<lyr.dim:\n",
    "                    diff = math.fabs(data[k]-lyr.neus[i].value)\n",
    "                    lyr.neus[i].wt[winner1] += learningConst/l*(1-diff/(l*interval));\n",
    "                i=i+1\n",
    "                \n",
    "            max2 = 0\n",
    "            for i in range(lyr.dim):\n",
    "                max2= max(max2,lyr.neus[i].wt[winner1]);\n",
    "                \n",
    "                \n",
    "            for i in range(lyr.dim):\n",
    "                lyr.neus[i].wt[winner1] = lyr.neus[i].wt[winner1]/max2\n",
    "                \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e1-le1) <= epsilon) and (math.fabs(e2-le2) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "        le1 = e1\n",
    "        e1 = 0\n",
    "        le2 = e2\n",
    "        e2 = 0\n",
    "     \n",
    "        \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlvq(nw,data,ndx):\n",
    "    e=0\n",
    "    le=0\n",
    "    iterations=0\n",
    "    min2=0\n",
    "    widthFactor=0\n",
    "    interval=0\n",
    "    temp=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            e+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e-le) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "            \n",
    "        le = e\n",
    "        e = 0\n",
    "        \n",
    "    lyr=nw.layers[1]\n",
    "    for j in range(lyr.dim):\n",
    "        if (j==lyr.dim-1):\n",
    "            widthFactor = math.fabs(lyr.neus[j].value - lyr.neus[j-1].value)/mlvq_lwidth\n",
    "        elif (j==0):\n",
    "            widthFactor = math.fabs(lyr.neus[j].value - lyr.neus[j+1].value)/mlvq_lwidth\n",
    "        else:\n",
    "            min2=min(math.fabs(lyr.neus[j].value - lyr.neus[j-1].value), math.fabs(lyr.neus[j].value-lyr.neus[j+1].value))\n",
    "            widthFactor=min2/mlvq_lwidth\n",
    "        \n",
    "        interval=(max1-min1)/nw.layers[2].dim\n",
    "        cur=min1\n",
    "        \n",
    "        for i in range(nw.layers[2].dim):\n",
    "            temp=0-pow(cur-lyr.neus[j].value,2)/widthFactor\n",
    "            nw.layers[2].neus[i].wt[j]=math.exp(temp)\n",
    "            cur += interval\n",
    "            \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfkp(nw,data,ndx):\n",
    "    e=0\n",
    "    le=0\n",
    "    iterations=0\n",
    "    min2=0\n",
    "    widthFactor=0\n",
    "    interval=0\n",
    "    temp=0\n",
    "    min1=max1=data[0]\n",
    "    \n",
    "    for k in range(train_num_line):\n",
    "        max1=max(max1,data[k])\n",
    "        min1=min(min1,data[k])\n",
    "    for j in range(1,nw.num_layers):\n",
    "        lyr=nw.layers[j]\n",
    "        for i in range(lyr.dim):\n",
    "            lyr.neus[i].value=min1+(i+0.5)/(lyr.dim)*(max1-min1)\n",
    "    \n",
    "    alpha=[0]*nw.layers[1].dim\n",
    "    beta=[0]*nw.layers[1].dim\n",
    "    sigma=[0]*nw.layers[1].dim\n",
    "    tau=[0]*nw.layers[1].dim\n",
    "    phi=[0]*nw.layers[1].dim\n",
    "    \n",
    "    \n",
    "    while(1):\n",
    "        for k in range(train_num_line):\n",
    "            winner1=findWinner(data[k],nw.layers[1])\n",
    "            nw.layers[1].neus[winner1].value *= (1-learningConst)\n",
    "            nw.layers[1].neus[winner1].value += learningConst*data[k];\n",
    "            e+= math.fabs(data[k]-nw.layers[1].neus[winner1].value)\n",
    "            \n",
    "        iterations=iterations+1\n",
    "        \n",
    "        if (math.fabs(e-le) <= epsilon):\n",
    "            print(\"No. of iterations =\", iterations);\n",
    "            break;\n",
    "            \n",
    "        le = e\n",
    "        e = 0\n",
    "        \n",
    "    le = 0 \n",
    "    e = 0\n",
    "    lyr = nw.layers[1]\n",
    "    for j in range(lyr.dim):\n",
    "        phi[j] = alpha[j] = beta[j] = sigma[j] = tau[j] = lyr.neus[j].value;\n",
    "        \n",
    "    for k in range(train_num_line):\n",
    "        winner= findWinner(data[k], nw.layers[1])\n",
    "        phi[winner] *= (1-pfkp_lwidth);\n",
    "        phi[winner] += pfkp_lwidth*data[k];\n",
    "        if(winner):\n",
    "            alpha[winner]=sigma[winner-1]\n",
    "        else:\n",
    "            alpha[winner] = min(alpha[winner],data[k])\n",
    "        beta[winner]= min(beta[winner],phi[winner])\n",
    "        sigma[winner]= max(sigma[winner],phi[winner])\n",
    "        if(winner == nw.layers[1].dim - 1):\n",
    "            tau[winner]= max(tau[winner],data[k])\n",
    "        else:\n",
    "            tau[winner] = beta[winner+1]\n",
    "            \n",
    "    lyr=nw.layers[2]\n",
    "    for j in range(nw.layers[1].dim):\n",
    "        for i in range(lyr.dim):\n",
    "            if(lyr.neus[i].value <= alpha[j] or lyr.neus[i].value >=tau[j]):\n",
    "                lyr.neus[i].wt[j]=0\n",
    "            elif(lyr.neus[i].value < beta[j]):\n",
    "                slope = 1/(beta[j]-alpha[j])\n",
    "                lyr.neus[i].wt[j] = slope * (lyr.neus[i].value - alpha[j])\n",
    "            elif(lyr.neus[i].value >= beta[j] and lyr.neus[i].value <=sigma[j]):\n",
    "                lyr.neus[i].wt[j]=1\n",
    "            else: \n",
    "                slope = 1/(sigma[j]-tau[j])\n",
    "                lyr.neus[i].wt[j]= slope * (lyr.neus[i].value - tau[j]) \n",
    "            \n",
    "    return nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def printCluster(nw,ndx):\n",
    "        \n",
    "    f = open(\"cluster_dct.txt\", \"a\")\n",
    "    f.write(\" \")\n",
    "    f.write(str(nw.layers[2].dim))\n",
    "    f.write(\"\\n \")\n",
    "    \n",
    "    fd = open(\"mf_dct.txt\", \"a\")\n",
    "    print(nw.layers[2].dim)\n",
    "    val=[]*nw.layers[2].dim\n",
    "    for j in range(nw.layers[2].dim):\n",
    "        val.append(round(nw.layers[2].neus[j].value,6))\n",
    "        f.write(str(val[j]))\n",
    "        f.write(\" \")\n",
    "        fd.write(str(val[j]))\n",
    "        fd.write(\"\\n\")\n",
    "    f.write(\"\\n \")\n",
    "            \n",
    "    i=0\n",
    "    wt=[0]*nw.layers[1].dim*nw.layers[2].dim\n",
    "    for j in range(nw.layers[1].dim):\n",
    "        for k in range(nw.layers[2].dim):\n",
    "            wt[i]=nw.layers[2].neus[k].wt[j]\n",
    "            f.write(str(round(wt[i],6)))\n",
    "            f.write(\" \")\n",
    "            fd.write(str(round(wt[i],6)))\n",
    "            fd.write(\"\\n\")\n",
    "            i=i+1\n",
    "        f.write(\"\\n \")\n",
    "    f.close()   \n",
    "    fd.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return network \n",
    "def initNN(ndx):\n",
    "    x=[]\n",
    "    nw=network(3)\n",
    "    \n",
    "#########################  LAYER 1: INPUT LAYER  #############################\n",
    "    layer1=layer(1,0,x) #numofneurons, not ipneu, data\n",
    "    nw.addLayers(0,layer1) #(layernum, layer)\n",
    "    \n",
    "#######################  LAYER 2: CENTROID LAYER  #############################\n",
    "    layer2=layer(clusters,0,x) \n",
    "    nw.addLayers(1,layer2)\n",
    "#   for i in range(1):\n",
    "    buildConnections(layer1,layer2,0,0,1)\n",
    "    \n",
    "#######################  LAYER 3: MEMBERSHIP LAYER  #############################\n",
    "    layer3=layer(discreteSamplePoints,0,x)\n",
    "    nw.addLayers(2,layer3) \n",
    "    for i in range(clusters):\n",
    "        buildConnections(layer2,layer3,i,0,1)\n",
    "    f = open(\"cluster_dct.txt\", \"a\")\n",
    "    f.write(col_names[ndx])\n",
    "    f.close()\n",
    "    print(col_names[ndx])\n",
    "#     nw=mlvq(nw, data_train.iloc[:,ndx],ndx)\n",
    "    nw=dct(nw, data_train.iloc[:,ndx],ndx)\n",
    "#     nw=pfkp(nw, data_train.iloc[:,ndx],ndx)\n",
    "\n",
    "    printCluster(nw,ndx)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complement(neu):\n",
    "    return (1-neu.actFunc_arg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(neu):\n",
    "    return neu.actFunc_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def classifier(neus):\n",
    "    classification=0\n",
    "    min1 = neus.input[0].activation\n",
    "    \n",
    "    for i in range(1,neus.num_inputs):\n",
    "        if (min1>neus.input[i].activation):\n",
    "            classification=i\n",
    "            min1= neus.input[i].activation\n",
    "        \n",
    "    if (min1<0.5*neus.num_inputs):\n",
    "        return classification\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation(neus):\n",
    "    dev=0\n",
    "    \n",
    "    for i in range(neus.num_inputs):\n",
    "        dev+= math.fabs(neus.wt[i]-neus.input[i].activation)\n",
    "        \n",
    "    return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotProduct(neus):\n",
    "    sum=0\n",
    "    \n",
    "    for i in range(neus.num_inputs):\n",
    "        sum += neus.input[i].activation*neus.wt[i]\n",
    "            \n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCombFunc(neus,combfunc):\n",
    "    neus.combFunc = combfunc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setActFunc(neus,actfunc):\n",
    "    neus.actFunc = actfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initNN1(x):\n",
    "    nw = network(6)\n",
    "    nw.num_feature=num_input #input\n",
    "    nw.num_pattern=num_output #out\n",
    "    \n",
    "#########################  LAYER 1: INPUT LAYER  #############################\n",
    "    \n",
    "    # create input layer\n",
    "    lyr=layer(num_input,1,x) #dim,input neu, dataset\n",
    "    nw.addLayers(0,lyr)\n",
    "    \n",
    "#     print(\"layer 1 with \",nw.layers[0].dim,\" neurons\\n\");\n",
    "#     for j in range(nw.layers[0].dim):\n",
    "#         print(\"membership function of \\n\")\n",
    "#         print(nw.layers[0].ipneus[j].mf,\"\\n\") \n",
    "\n",
    "\n",
    "\n",
    "#######################  LAYER 2: ANTECEDENT LAYER  #############################\n",
    "    \n",
    "    # create antecedent layer\n",
    "    lyr=layer(num_input*num_output,0,x) #dim, not input neu, dataset\n",
    "    nw.addLayers(1,lyr)\n",
    "    \n",
    "    # make connections between antecedent and input layers\n",
    "    for i in range(nw.num_feature):\n",
    "        for j in range(nw.num_pattern):\n",
    "            neu = lyr.neus[i*nw.num_pattern+j]\n",
    "            neu.ip_type=0\n",
    "            neu.ipneu_input[0]=nw.layers[0].ipneus[i]\n",
    "            neu.wt[0]=1.0\n",
    "            neu.num_inputs=1   \n",
    "            \n",
    "    \n",
    "#######################  LAYER 3: RULE BASE LAYER  #############################\n",
    "    \n",
    "    # create clause combination layer\n",
    "    lyr=layer(num_output,0,x) #dim, not input neu, dataset\n",
    "    nw.addLayers(2,lyr)\n",
    "    \n",
    "    # make connections between clause combination and antecedent layers\n",
    "    for i in range(lyr.dim):\n",
    "        total=0\n",
    "        lyr.neus[i].num_inputs = nw.num_feature\n",
    "        setCombFunc(lyr.neus[i],0) #DotProduct\n",
    "        setActFunc(lyr.neus[i],1) #complement\n",
    "        for j in range(nw.num_feature):\n",
    "            lyr.neus[i].input[j] = nw.layers[1].neus[j*nw.num_pattern+i]\n",
    "        for j in range(nw.num_feature):\n",
    "            lyr.neus[i].wt[j]=1/calcIntersection(nw,i,j);\n",
    "            #print(\"i:\",i,\" j:\",j)\n",
    "            total+=lyr.neus[i].wt[j]\n",
    "        for j in range(nw.num_feature):\n",
    "            lyr.neus[i].wt[j] /= total\n",
    "            \n",
    "\n",
    "#################  LAYER 4: POSSIBILITY DISTRIBUTION LAYER  #############################\n",
    "    \n",
    "    # create possibility distribution layer\n",
    "    lyr = layer(nw.num_pattern*nw.num_pattern,0,x)\n",
    "    nw.addLayers(3,lyr)\n",
    "    \n",
    "    # make connections btwn possibility distribution and caluse combination layers\n",
    "    for i in range(nw.num_pattern):\n",
    "        for j in range(nw.num_pattern):\n",
    "            neu=lyr.neus[i*nw.num_pattern+j]\n",
    "            setCombFunc(neu,0) #DotProduct\n",
    "            setActFunc(neu,1) #complement\n",
    "            neu.input[0]=nw.layers[2].neus[i]\n",
    "            if (i==j):\n",
    "                neu.wt[0]=0\n",
    "            else:\n",
    "                neu.wt[0]=1\n",
    "            neu.num_inputs=1\n",
    "    \n",
    "    \n",
    "#################  LAYER 5: OUTPUT DEVIATION LAYER  #############################\n",
    " \n",
    "    # create output deviation layer\n",
    "    lyr = layer(nw.num_pattern, 0, x)\n",
    "    nw.addLayers(4,lyr)\n",
    "    \n",
    "    # make connections btwn output dev and poss dis layers\n",
    "    for i in range(lyr.dim):\n",
    "        lyr.neus[i].num_inputs = nw.num_pattern\n",
    "        setCombFunc(lyr.neus[i],1) #deviation\n",
    "        setActFunc(lyr.neus[i],0) #linear\n",
    "        for j in range(nw.num_pattern):\n",
    "            lyr.neus[i].input[j] = nw.layers[3].neus[i*nw.num_pattern+j]\n",
    "            if (i==j):\n",
    "                lyr.neus[i].wt[j]=1\n",
    "            else:\n",
    "                lyr.neus[i].wt[j]=0\n",
    "    \n",
    "\n",
    "#################  LAYER 6: OUTPUT DEVIATION LAYER  #############################\n",
    "\n",
    "    #create final layer\n",
    "    lyr = layer(1,0,x)\n",
    "    nw.addLayers(5,lyr)\n",
    "    \n",
    "    # make connections btwn final and output deviation layers\n",
    "    lyr.neus[0].num_inputs=nw.num_pattern\n",
    "    setCombFunc(lyr.neus[0],2) #classifier\n",
    "    setActFunc(lyr.neus[0],0) #linear\n",
    "    for i in range(nw.num_pattern):\n",
    "        lyr.neus[0].input[i] = nw.layers[4].neus[i]\n",
    "\n",
    "    \n",
    "    yagerTest(nw)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neus.combFunc={{none,-1},{dotProduct,0},{deviation,1},{classifier,2} };\n",
    "#neus.actFunc={{none,-1},{linear,0}, {complement,1} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIntersection(nw,cluster, feature):\n",
    "    intersection=0\n",
    "    ipneu=nw.layers[0].ipneus[feature]\n",
    "    \n",
    "    mf=ipneu.mf\n",
    "    for i in range(1,nw.num_pattern+1):\n",
    "        if (cluster != i-1):\n",
    "            for j in range(ipneu.numPt):\n",
    "                intersection+=min(mf[cluster+1][j],mf[i][j])\n",
    "\n",
    "    if (intersection==0):\n",
    "        return 0.001\n",
    "    else:\n",
    "        return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yagerTest(nw):\n",
    "    correct=0\n",
    "    wrong=0\n",
    "    train_output=[0]*train_num_line\n",
    "    train_feature = (data_train.iloc[:,[0,1,2,3]]).values\n",
    "    train_pattern = (data_train.iloc[:,[4]]).values\n",
    "    test_feature = (data_test.iloc[:,[0,1,2,3]]).values\n",
    "    test_pattern = (data_test.iloc[:,[4]]).values\n",
    "    #print(feature)\n",
    "\n",
    "    for i in range(train_num_line):\n",
    "        processInput_train(nw,train_feature[i],train_pattern[i],i)\n",
    "        #mfCluster_y[i]=pattern[i][0]\n",
    "        train_output[i]=activateNetwork(nw);\n",
    "        \n",
    "    f = open(\"result_fnn_dct.txt\", \"w\")\n",
    "        \n",
    "    for i in range(train_num_line):\n",
    "        if train_output[i] == train_pattern[i][0]:\n",
    "            print(\"correct:\",train_output[i],\" \",train_pattern[i][0])\n",
    "            f.write(\"correct: \")\n",
    "            f.write(str(train_output[i]))\n",
    "            f.write(\" \")\n",
    "            f.write(str(train_pattern[i][0]))\n",
    "            f.write(\"\\n\")\n",
    "            correct+=1\n",
    "        else:\n",
    "            print(\"wrong:\",train_output[i],\" \",train_pattern[i][0]) \n",
    "            f.write(\"wrong: \")\n",
    "            f.write(str(train_output[i]))\n",
    "            f.write(\" \")\n",
    "            f.write(str(train_pattern[i][0]))\n",
    "            f.write(\"\\n\")\n",
    "            wrong+=1\n",
    "            \n",
    "    print(\"Classification rate:\",correct/train_num_line)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Classification rate: \")\n",
    "    f.write(str(correct/train_num_line))\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    for i in range(test_num_line):\n",
    "        processInput_test(nw,test_feature[i],test_pattern[i],i)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activateNetwork(nw):\n",
    "    for i in range(nw.layers[1].dim):\n",
    "        neu=nw.layers[1].neus[i]\n",
    "        neu.activation=neu.ipneu_input[0].value[i%nw.num_pattern]\n",
    "\n",
    "    for j in range(2,nw.num_layers):\n",
    "        for i in range(nw.layers[j].dim):\n",
    "            neu = nw.layers[j].neus[i]\n",
    "            if(neu.combFunc==0):\n",
    "                neu.actFunc_arg[0] = dotProduct(neu)\n",
    "            if(neu.combFunc==1):\n",
    "                neu.actFunc_arg[0] = deviation(neu)\n",
    "            if(neu.combFunc==2):\n",
    "                neu.actFunc_arg[0] = classifier(neu)\n",
    "                \n",
    "            if(neu.actFunc==0):\n",
    "                neu.activation = linear(neu)\n",
    "            if(neu.actFunc==1):\n",
    "                neu.activation = complement(neu)\n",
    "    \n",
    "    return nw.layers[5].neus[0].activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInput_train(nw,x,y,count):\n",
    "    \n",
    "    for i in range(nw.num_feature):\n",
    "        ipneu=nw.layers[0].ipneus[i]\n",
    "        ipneu.ip_value=x[i]\n",
    "        mf=ipneu.mf\n",
    "        ##find the disagreement score for input value\n",
    "        winner=findWinner1(x[i],mf[0],ipneu.numPt)\n",
    "        for j in range(clusters):\n",
    "            ipneu.value[j] = 1-mf[j+1][winner]\n",
    "            fuzzytrain_x[count][(i*clusters)+j]=mf[j+1][winner]#ipneu.value[j]\n",
    "        \n",
    "        ##find the similarity score for output value             \n",
    "        winner=findWinner1(y[0],outmf[0],ipneu.numPt)\n",
    "        for j in range(clusters):\n",
    "            fuzzytrain_y[count][j] = outmf[j+1][winner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInput_test(nw,x,y,count):\n",
    "    \n",
    "    for i in range(nw.num_feature):\n",
    "        ipneu=nw.layers[0].ipneus[i]\n",
    "        ipneu.ip_value=x[i]\n",
    "        mf=ipneu.mf\n",
    "        ##find the disagreement score for input value\n",
    "        winner=findWinner1(x[i],mf[0],ipneu.numPt)\n",
    "        for j in range(clusters):\n",
    "            ipneu.value[j] = 1-mf[j+1][winner]\n",
    "            fuzzytest_x[count][(i*clusters)+j]=mf[j+1][winner]#ipneu.value[j]\n",
    "        \n",
    "        ##find the similarity score for output value             \n",
    "        winner=findWinner1(y[0],outmf[0],ipneu.numPt)\n",
    "        for j in range(clusters):\n",
    "            fuzzytest_y[count][j] = outmf[j+1][winner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength\n",
      "No. of iterations = 13\n",
      "50\n",
      "SepalWidth\n",
      "No. of iterations = 33\n",
      "50\n",
      "PetalLength\n",
      "No. of iterations = 9\n",
      "50\n",
      "PetalWidth\n",
      "No. of iterations = 18\n",
      "50\n",
      "TYPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-8f886a337ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_input\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0minitNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mf_dct.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-ad60931b4c00>\u001b[0m in \u001b[0;36minitNN\u001b[1;34m(ndx)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mndx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#     nw=mlvq(nw, data_train.iloc[:,ndx],ndx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mnw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;31m#     nw=pfkp(nw, data_train.iloc[:,ndx],ndx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e7f32ebc2a1b>\u001b[0m in \u001b[0;36mdct\u001b[1;34m(nw, data, ndx)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlyr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[0mlyr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwinner1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlyr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwinner1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmax2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "num_var=num_input+num_output\n",
    "x=[]\n",
    "f = open(\"cluster_dct.txt\", \"w\")\n",
    "f.write(str(num_input))\n",
    "f.write(str(num_output))\n",
    "f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "fd = open(\"mf_dct.txt\", \"w\")\n",
    "fd.close()\n",
    "\n",
    "for i in range(num_input+1):\n",
    "    initNN(i)\n",
    "\n",
    "with open('mf_dct.txt', 'r') as f:\n",
    "    i = f.read().split()\n",
    "    for elem in i:\n",
    "        try:\n",
    "            x.append(float(elem))\n",
    "        except ValueError:\n",
    "            pass\n",
    "print(len(x))\n",
    "\n",
    "outmf=[[0 for i in range(discreteSamplePoints)] for j in range(clusters+1)]    \n",
    "fuzzytrain_x = [[0 for i in range((num_input*clusters))] for j in range(train_num_line)]   \n",
    "fuzzytrain_y = [[0 for i in range((clusters))] for j in range(train_num_line)]\n",
    "fuzzytest_x = [[0 for i in range((num_input*clusters))] for j in range(test_num_line)]   \n",
    "fuzzytest_y = [[0 for i in range((clusters))] for j in range(test_num_line)] \n",
    "initNN1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "fuzzytrain_x = numpy.array(fuzzytrain_x)\n",
    "fuzzytrain_y = numpy.array(fuzzytrain_y)\n",
    "\n",
    "print(\"Shape of X\",fuzzytrain_x.shape)\n",
    "print(\"Shape of y\",fuzzytrain_y.shape)\n",
    "print(\"Examples of X\\n\",fuzzytrain_x[:3])\n",
    "print(\"Examples of y\\n\",fuzzytrain_y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzytest_x = numpy.array(fuzzytest_x)\n",
    "fuzzytest_y = numpy.array(fuzzytest_y)\n",
    "\n",
    "print(\"Shape of X\",fuzzytest_x.shape)\n",
    "print(\"Shape of y\",fuzzytest_y.shape)\n",
    "print(\"Examples of X\\n\",fuzzytest_x[:3])\n",
    "print(\"Examples of y\\n\",fuzzytest_y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras.utils import np_utils\n",
    "# mfCluster_y=np_utils.to_categorical(mfCluster_y,num_classes=3)\n",
    "print(\"Shape of y_train\",fuzzytrain_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    global fuzzytrain_x\n",
    "    global fuzzytrain_y\n",
    "    \n",
    "    mlp=Sequential()\n",
    "    print('x[0]:',x[0],' x[1]:',x[1],' x[2]:',x[2])\n",
    "    f = open(\"GA_3layers_200_100_200.txt\", \"a\")\n",
    "    f.write(\"x[0]:\")\n",
    "    f.write(str(x[0]))\n",
    "    f.write(\"x[1]:\")\n",
    "    f.write(str(x[1]))\n",
    "    f.write(\"x[2]:\")\n",
    "    f.write(str(x[2]))\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    mlp.add(Dense(x[0],input_dim=num_input*clusters,activation='relu'))\n",
    "    mlp.add(Dense(x[1],activation='relu'))\n",
    "    mlp.add(Dense(x[2],activation='relu'))\n",
    "    mlp.add(Dropout(0.2))\n",
    "    mlp.add(Dense(clusters,activation='softmax'))\n",
    "    mlp.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    #mlp.fit(mfCluster_x,mfCluster_y,validation_data=(mfCluster_x,mfCluster_y),batch_size=20,epochs=20,verbose=1)\n",
    "    mlp.fit(fuzzytrain_x,fuzzytrain_y,validation_data=(fuzzytest_x,fuzzytest_y),batch_size=20,epochs=70,verbose=1)\n",
    "\n",
    "    prediction=mlp.predict(fuzzytest_x)\n",
    "    length=len(prediction)\n",
    "    actual=np.argmax(fuzzytest_y,axis=1)\n",
    "    predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "    accuracy=np.sum(actual==predict_label)/length * 100 \n",
    "    f.write(\"Accuracy of the dataset: \")\n",
    "    f.write(str(accuracy))\n",
    "    f.write(\"\\n\\n\")\n",
    "    print(\"Accuracy of the dataset: \",accuracy,\"\\n\")\n",
    "    \n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from geneticalgorithm import geneticalgorithm as ga\n",
    "# f = open(\"GA_3layers_200_100_200.txt\", \"w\")\n",
    "# varbound=np.array([[1,200],[1,100],[1,200]])\n",
    "# vartype=np.array([['int'],['int'],['int']])\n",
    "\n",
    "# model=ga(function=mlp,dimension=3,variable_type_mixed=vartype,variable_boundaries=varbound)\n",
    "\n",
    "# model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp=Sequential()\n",
    "mlp.add(Dense(500,input_dim=num_input*clusters,activation='elu'))\n",
    "# mlp.add(Dense(200,activation='relu'))\n",
    "# mlp.add(Dense(200,activation='relu'))\n",
    "mlp.add(Dropout(0.2))\n",
    "mlp.add(Dense(clusters,activation='softmax'))\n",
    "mlp.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(fuzzytrain_x,fuzzytrain_y,validation_data=(fuzzytest_x,fuzzytest_y),batch_size=20,epochs=20,verbose=1)\n",
    "\n",
    "prediction=mlp.predict(fuzzytest_x)\n",
    "length=len(prediction)\n",
    "actual=np.argmax(fuzzytest_y,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(actual==predict_label)/length * 100 \n",
    "print(\"Accuracy of the dataset\",accuracy,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "correct=0\n",
    "wrong=0\n",
    "f = open(\"result_fmlp_dct.txt\", \"w\")\n",
    "for i in range(len(predict_label)):\n",
    "    if predict_label[i] == actual[i]:\n",
    "        print(\"correct:\",predict_label[i],\" \",actual[i])\n",
    "        f.write(\"correct: \")\n",
    "        f.write(str(predict_label[i]))\n",
    "        f.write(\" \")\n",
    "        f.write(str(actual[i]))\n",
    "        f.write(\"\\n\")\n",
    "        correct+=1\n",
    "    else:\n",
    "        print(\"wrong:\",predict_label[i],\" \",actual[i]) \n",
    "        f.write(\"wrong: \")\n",
    "        f.write(str(predict_label[i]))\n",
    "        f.write(\" \")\n",
    "        f.write(str(actual[i]))\n",
    "        f.write(\"\\n\")\n",
    "        wrong+=1\n",
    "            \n",
    "print(\"Classification rate:\",correct/len(predict_label))\n",
    "f.write(\"\\n\")\n",
    "f.write(\"Classification rate: \")\n",
    "f.write(str(correct/len(predict_label)))\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
